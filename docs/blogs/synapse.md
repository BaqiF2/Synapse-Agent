# Synapse Agent：统一 Shell 抽象与技能进化

> 如果大脑是一台生物计算机，那**神经突触**就是它的编程语言——每一次学习，都是在重写突触连接的权重。

---

## 一、Synapse——神经突触

**Synapse**，神经突触。

在生物学中，突触是两个神经元之间的连接点。它不仅传递信号——本身就是记忆的载体。"一起激活的神经元会连接在一起"，这条 Hebbian Learning 法则，是整个神经可塑性的基石。

这也是这个项目名称的由来。

过去一年，我深度使用了 Claude Code、Cursor 等工具，也研究了多个 Agent 框架。一个问题反复浮现：**现在的 Agent 每次对话都在"失忆"**。它们像一个每天醒来就忘记前一天经验的实习生，但永远在重复学习同样的东西。

能不能造一个会"学习"和"记忆"的 Agent？

不是靠更大的上下文窗口暴力记忆，而是像大脑一样——**把反复出现的模式沉淀为稳定的突触连接**，下次遇到类似任务时自动激活。

带着这个问题，我决定从零开始构建 Synapse Agent，用它来验证我对 AI Agent 的理解。

---

## 二、八条核心直觉

项目启动前，我写下了八条关于 Agent 的核心直觉。它们分为两类——**已知定律**和**需要证明的命题**。

### 已知定律

这三条是我从实践中确认的事实，不需要额外证明：

| # | 直觉 | 一句话解释 |
|---|------|-----------|
| 1 | **工具就是 Agent 的手脚** | 没有工具的 Agent 只是一个聊天机器人 |
| 4 | **文件系统是一种记忆** | 文件不会随对话消失，天然具备跨会话持久性 |
| 5 | **技能 = 文件系统 + 工具** | 把经验写成文件，把操作封装为工具，就得到了可复用的技能 |

### 需要证明的命题

这五条是我的假设，Synapse Agent 的设计就是对它们的逐一验证：

| # | 命题 | 对应的设计 |
|---|------|-----------|
| 2 | **一切工具都是 Bash** | 三层 Shell 架构——LLM 只学一个工具 |
| 3 | **一切都是工具** | 子任务、技能管理全部封装为命令 |
| 6 | **技能 + LLM = 大脑** | 技能系统——自我学习与记忆 |
| 7 | **技能 + LLM + Bash = 通用智能体** | 技能中的工具自动转化为 Shell Command |
| 8 | **沙盒 = 一种工作台** | 安全执行环境——重要但非核心 |

接下来的章节，我将逐一展开这些命题。

---

## 三、命题一：一切工具都是 Shell Command

### 3.1 问题：工具爆炸

主流 Agent 框架给 LLM 提供大量工具定义——读文件一个工具，写文件一个工具，搜索一个工具……每个工具都有一段 JSON Schema。对 LLM 来说，每多一个工具，就多一重选择负担。

> 如果你的大脑每次要抬手，都需要先从一张清单里"选择"用哪块肌肉——你连杯水都端不起来。

**能不能让 LLM 只学一个工具？**

### 3.2 灵感：运动皮层与 Unix 哲学

人类的**运动皮层**给了我灵感。大脑只有一个运动中枢，却能协调全身 600 多块肌肉。它不需要为每块肌肉设计独立的"决策模块"——只需发出高层意图，底层神经通路自动路由到正确的肌肉群。

Unix 哲学也提供了答案：**"一切皆文件"**。磁盘是文件，网络是文件，设备是文件——统一抽象让一切操作都可以用 `read/write` 完成。

类比到 Agent：**"一切工具皆 Shell Command"**。Shell 是人类用了 50 年的工具协议，LLM 天生理解 `ls`、`git`、`curl` 的用法。与其教 LLM 学全新的工具 API，不如让所有工具"说 Shell 的语言"。

### 3.3 三层架构：神经通路的三种类型

人类的神经通路大致分为三种：先天反射（脊髓反射弧）、后天习得的运动技能（小脑协调）、以及通过学习建立的跨模态连接。Synapse 的三层 Shell 架构与之对应：

```
┌──────────────────────────────────────────────────┐
│              BashTool (唯一入口)                   │
│       —— LLM 的"运动皮层"，只此一个工具 ——        │
├──────────────────────────────────────────────────┤
│              BashRouter (路由器)                   │
│       —— 注意力机制：根据命令模式自动路由 ——       │
├───────────────┬────────────────┬─────────────────┤
│    Layer 1    │    Layer 2     │     Layer 3     │
│ Native Shell  │  Agent Shell   │ Extension Shell │
│               │                │                 │
│  先天反射      │  后天习得       │  跨模态迁移     │
│  ls, git,     │  read, write,  │  mcp:server:*   │
│  npm, curl    │  edit, task:*  │  skill:name:*   │
│               │                │                 │
│  零适配成本    │  为 Agent 优化  │  自动包装为命令  │
│  复用整个      │  的文件操作和   │  外部工具无缝   │
│  Unix 生态     │  任务管理命令   │  接入           │
└───────────────┴────────────────┴─────────────────┘
```

**Layer 1 — 先天反射（Native Shell）**

`ls`、`git`、`npm`、`curl`……操作系统自带的命令。零适配成本，直接复用整个 Unix 生态。

**Layer 2 — 后天习得（Agent Shell）**

`read`、`write`、`edit`、`task:explore`、`skill:load`……为 Agent 专门设计的命令，封装了文件操作、子任务分发、技能管理等能力，语法与 Unix 命令一致。

**Layer 3 — 跨模态迁移（Extension Shell）**

`mcp:github:create_issue`、`skill:blog-writer:generate`……外部工具自动包装成的命令。MCP 协议工具、Skill 脚本，都被自动转化为 Shell Command，对 LLM 完全透明。

### 3.4 BashRouter：注意力机制

`BashRouter` 是这个架构的关键枢纽。它的角色类似 Transformer 中的**注意力机制**——根据输入的命令模式，自动路由到对应的处理器：

```
                    LLM 输出命令
                         │
                         ▼
                    ┌─────────┐
                    │BashRouter│
                    └────┬────┘
                         │
            ┌────────────┼────────────┐
            │            │            │
            ▼            ▼            ▼
    以 mcp: 开头？  匹配注册表？    都不匹配？
            │            │            │
            ▼            ▼            ▼
    Extension Shell  Agent Shell   Native Shell
    (McpHandler)    (Read/Write    (直接执行)
                     /Task/...)
```

LLM 不需要知道背后有三层处理器——它只需要输入命令，BashRouter 自动将命令分发到正确的处理器。

### 3.5 效果对比

| | 传统方案 | Synapse 方案 |
|---|---------|-------------|
| **工具数量** | N 个工具，N 段 JSON Schema | **1 个 BashTool**，22 行描述 |
| **新工具接入** | 新增 JSON Schema，LLM 重新学习 | 新增命令前缀，**无需修改工具定义** |
| **LLM 认知负担** | 随工具数量线性增长 | **恒定不变** |

### 3.6 扩展命令的统一包装

外部工具是如何变成 Shell Command 的？答案是**自动包装**：

```
外部工具                          转换器                     Shell Command
───────────────────────────────────────────────────────────────────────

MCP Server                                                mcp:github:create_issue
  └─ tools/create_issue    ──→  McpWrapperGenerator  ──→    ├── 支持 --help
  └─ tools/list_repos      ──→                       ──→    ├── 支持位置参数
                                                            └── 对 LLM 完全透明

Skill 脚本                                                skill:blog:generate
  └─ scripts/generate.py   ──→  SkillWrapperGenerator ──→   ├── 支持 --help
  └─ scripts/validate.sh   ──→                        ──→   ├── 支持位置参数
                                                            └── 对 LLM 完全透明
```

转换器读取外部工具的参数定义，自动生成 Shell Command 包装。LLM 只看到一个命令名和 `--help` 输出——就像你的手不需要知道是肌肉在收缩还是肌腱在传力，大脑只需说"抓住杯子"。

### 3.7 按需检索：海马体的线索回忆

你可能会问：这么多扩展工具，Agent 怎么知道有哪些可用？

答案是——**它不知道，直到需要的时候去搜。**

Synapse 不会把所有扩展工具预加载到上下文中。Agent 启动时只带着 Layer 1 和 Layer 2 的基础能力。当它遇到一个需要额外工具的任务时，会主动调用 `command:search` 在三层工具库中搜索：

```
Agent 遇到未知任务
        │
        ▼
command:search "关键词"
        │
        ▼
┌───────────────────────────────────┐
│         三层工具库                  │
│  Native Shell ← 系统自带           │
│  Agent Shell  ← 内置注册           │
│  Extension    ← MCP/Skill 安装    │
└───────────────────────────────────┘
        │
        ▼
返回匹配的命令列表
        │
        ▼
Agent 选择并执行（先 --help 再使用）
```

这就像大脑的**海马体检索机制**——你不会把所有记忆都放在意识前台，而是通过"线索"触发回忆。`command:search` 就是 Agent 的线索检索。

这带来一个重要好处：**工具库可以无限扩展，但上下文成本恒定**。无论安装了 10 个还是 1000 个 MCP 工具，Agent 只在需要时搜索，只加载用到的。

---

## 四、命题二：技能 + LLM = 大脑

### 4.1 问题：Agent 没有记忆

如果说统一 Shell 解决了 Agent "如何行动"的问题，那技能系统要解决的就是"如何记忆"。

现在的 LLM Agent 有一个根本性问题：**每次对话都是"失忆"状态**。它就像一个只有**工作记忆**、没有**长期记忆**的大脑——能在当下解决问题，但无法把经验带到未来。

人类怎么解决这个问题？写笔记、整理 SOP——把短期经验沉淀为长期知识。Agent 也应该可以。

### 4.2 设计思路：文件系统就是突触权重

在我的原始构想中，核心公式是：

> **技能 = 文件系统 + 工具**

这条公式的灵感来自神经科学：LLM 的参数是大脑的"先天结构"，**文件系统就是后天形成的突触权重**。技能文件持久化在磁盘上，跨会话保持，每次对话后可被更新强化——就像学习让突触连接变得更强。

```
┌─────────────────────────────────────────┐
│              LLM (先天结构)              │
│         大量参数 = 预训练知识            │
│  ┌─────────────────────────────────┐    │
│  │          上下文窗口              │    │
│  │       = 工作记忆                 │    │
│  │   (当前对话 + 加载的技能)        │    │
│  └─────────────────────────────────┘    │
└───────────────┬─────────────────────────┘
                │ 读取/写入
                ▼
┌─────────────────────────────────────────┐
│        ~/.synapse/skills/               │
│        = 突触权重 (长期记忆)            │
│                                         │
│   技能文件持久化在磁盘上                │
│   跨会话保持，反复强化                  │
└─────────────────────────────────────────┘
```

### 4.3 技能的结构

每个技能是一个自包含的目录，结构如下：

```
skill-name/
├── SKILL.md          ← 技能说明书（何时触发、怎么执行）
├── scripts/          ← 可执行脚本（确定性操作，无需消耗 token）
├── references/       ← 参考资料（按需加载的领域知识）
└── assets/           ← 输出资源（模板、图片等）
```

- **SKILL.md** 是技能的"大纲"——何时用、怎么用
- **scripts/** 可直接执行的脚本，把确定性操作固化，避免 LLM 每次重写
- **references/** 领域知识文档，按需加载，不浪费上下文
- **assets/** 模板和资源文件，被最终输出引用

### 4.4 技能搜索与渐进式加载：检索 → 回忆 → 提取

与工具搜索类似，Synapse **不会预加载任何技能**。Agent 启动时对技能库一无所知——它甚至不知道自己"会什么"。

当遇到中高复杂度任务时，Agent 的第一步是**搜索**。它会启动一个专门的搜索子智能体（`task:skill:search`），在技能库中进行语义匹配：

```
Agent 接到复杂任务
        │
        ▼
task:skill:search "关键词"
        │
        ▼
┌──────────────────────────────────────┐
│        Skill Search Sub Agent        │
│  (纯推理，无工具权限)                 │
│                                      │
│  输入: 用户意图 + 全部技能元数据      │
│  输出: 语义匹配的技能名称列表         │
└──────────────────────────────────────┘
        │
        ▼
skill:load <精确名称>
        │
        ▼
技能指令进入上下文 → Agent 按指令执行
```

这背后是一个**三级检索**机制，对应大脑从线索到完整回忆的过程：

```
Level 0                      Level 1                     Level 2
搜索 (检索线索)               SKILL.md (<5k 词)           脚本/参考资料
──────────────────────────────────────────────────────────────────────

┌──────────────────┐   匹配    ┌──────────────────┐   按需    ┌──────────┐
│ skill:search     │─────────→│  # Blog Generator │─────────→│ scripts/ │
│ "写博客"          │          │                   │          │ refs/    │
│                  │          │  ## Quick Start   │          │ assets/  │
└──────────────────┘          │  ## Workflow      │          └──────────┘
                              │  ## Best Practice │
 Agent 不预知任何技能          │  ...              │           仅需要时加载
 需要时主动搜索               └──────────────────┘           (从长期记忆
                               skill:load 后                  中提取)
                               进入上下文
```

- **Level 0**：搜索——Agent 通过子智能体在技能库中语义检索，就像海马体通过线索搜索长期记忆
- **Level 1**：加载 SKILL.md——搜索到后通过 `skill:load` 将完整指令加载到上下文，相当于"回忆起"一段知识
- **Level 2**：脚本和参考资料按需读取，就像在回忆的基础上翻阅详细笔记

关键规则是：**永远不要猜测技能名称，必须先搜后用。** 就像你不能凭空"想起"一段从未编码的记忆——Agent 必须通过搜索确认技能存在，才能用精确名称加载。

这种设计让 Agent 可以拥有一个无限扩展的技能库，但上下文成本始终可控。

### 4.5 技能进化的三种方式

大脑通过**神经可塑性**不断重塑自己——反复练习的技能变得更快更准确，不用的连接逐渐弱化。Agent 的技能进化也有三种对应方式：

#### 方式一：Hebbian Learning——自动技能增强

> "一起激活的神经元会连接在一起。" —— Donald Hebb

这是最自然的进化方式。Agent 在完成任务后，SkillEnhancer 会分析对话历史，检测工具使用模式：

```
用户任务 ──→ Agent 执行 ──→ 对话历史
                                │
                         分析工具使用序列
                        (检测重复模式)
                          ↙          ↘
                  创建新技能      增强已有技能
                          ↘          ↙
                     技能库 (文件系统)
                             │
                      下次任务自动加载
```

这就像**在线学习（Online Learning）**——Agent 在执行任务中持续更新"参数"（技能库）。反复出现的"读文件 → 分析 → 写报告"模式会被固化为技能，下次直接调用。

#### 方式二：前额叶皮层——元技能指导

前额叶皮层是大脑的"高管"——它不直接干活，而是**监督和规划**其他脑区的工作。

Synapse 中有两个**元技能（Meta-Skill）**：

- **skill-creator**：指导 Agent 从零创建技能
- **skill-enhance**：指导 Agent 增强已有技能

这形成了自举循环：**技能在教 Agent 创造更好的技能**——就像元认知让人类不断改善学习方法。

```
┌─────────────────────────────────────┐
│           元技能 (前额叶)            │
│                                     │
│   skill-creator    skill-enhance    │
│   "如何创建技能"   "如何增强技能"    │
│         │                │          │
│         ▼                ▼          │
│     指导 Agent 创建/优化技能        │
│              │                      │
│              ▼                      │
│         技能库增长                   │
│              │                      │
│              ▼                      │
│      Agent 能力提升                  │
│              │                      │
│              ▼                      │
│   下次创建更好的技能 (自举循环)      │
└─────────────────────────────────────┘
```

#### 方式三：RLHF——用户主动导入技能

在机器学习中，**RLHF（人类反馈强化学习）** 是让模型对齐人类偏好的关键手段。在 Synapse 中，用户主动导入技能就是一种 RLHF：

- 用户通过 `skill:import` 从本地目录或 GitHub URL 导入优质技能
- 每次导入都是一个"奖励信号"，告诉 Agent **"这是好的做法"**
- 导入后 Agent 自动索引、分类，并在合适的任务中加载使用

自动增强是 Agent 自己"摸索"学到的，而用户导入是人类直接把"正确答案"交给 Agent——两者互补，构成完整的学习闭环。

```
┌───────────────────────────────────────────────────┐
│           技能进化 ≈ 神经可塑性                     │
│                                                   │
│   Hebbian Learning    前额叶监督        RLHF      │
│   (自动增强)          (元技能指导)     (用户导入)  │
│        ↘                  ↓               ↙       │
│           技能库 = 突触权重的持久化                  │
│              ~/.synapse/skills/                    │
│                       ↓                           │
│                 Agent 越用越强                      │
└───────────────────────────────────────────────────┘
```

---

## 五、命题三：一切都是工具

在 Agent Loop 中，如果你想给 Agent 加一个新能力——**先把它封装为工具**。

这条原则深刻影响了系统设计。子智能体是工具（`task:explore`），技能搜索是工具（`task:skill:search`），技能管理是工具（`skill:load`），工具搜索也是工具（`command:search`）。

为什么不硬编码到 Agent Loop 中？因为**工具化意味着 LLM 自主决策**——Agent 根据任务上下文判断是否需要搜索工具、加载技能、分发子任务，而不是被固定流程驱动。

| 功能需求 | 工具化方案 | 命令格式 |
|---------|-----------|---------|
| 读写文件 | Agent Shell | `read file.txt`、`write file.txt "content"` |
| 子任务分发 | Task 命令 | `task:explore "分析项目结构"` |
| 技能搜索 | Skill 子智能体 | `task:skill:search --prompt "代码分析"` |
| 技能管理 | Skill 命令 | `skill:load blog-gen` |
| 工具搜索 | Search 命令 | `command:search "部署"` |
| 外部 API | MCP 转换 | `mcp:github:create_issue --title "bug"` |

就像人类大脑中"一切都是神经信号"——无论是视觉、听觉还是运动指令，底层都是电化学信号在突触之间传递。在 Synapse 中，一切能力都是 Shell Command 在 BashRouter 中流动。

---

## 六、协同效应：完整的神经系统

当统一 Shell、技能系统和"一切工具化"组合在一起，会产生协同效应：

```
┌──────────────────────────────────────────────────────────┐
│                      Agent Runner                         │
│                    ("整个大脑")                            │
│                                                          │
│  ┌────────────────────────────────────────────────────┐  │
│  │                 System Prompt                       │  │
│  │          (技能元数据 + Agent Shell 语法)             │  │
│  │         —— 常驻的"工作记忆索引" ——                  │  │
│  └────────────────────────────────────────────────────┘  │
│                          ↕                               │
│                     LLM 推理                              │
│                   ("思考与决策")                           │
│                          ↕                               │
│  ┌────────────────────────────────────────────────────┐  │
│  │           BashTool → BashRouter                     │  │
│  │          ("运动皮层 → 神经通路")                     │  │
│  │  ┌────────────┬──────────────┬──────────────────┐  │  │
│  │  │  Native    │  Agent Shell │  Extension Shell │  │  │
│  │  │  Shell     │              │                  │  │  │
│  │  │  (反射)    │  (习得技能)   │  (迁移能力)      │  │  │
│  │  └────────────┴──────────────┴──────────────────┘  │  │
│  └────────────────────────────────────────────────────┘  │
│                          ↕                               │
│  ┌──────────────────┐  ┌──────────────────────────────┐  │
│  │   Sub Agents     │  │      Skill System            │  │
│  │  ("专注脑区")     │  │    ("长期记忆系统")          │  │
│  │                  │  │                              │  │
│  │  explore: 感知   │  │  加载 → 使用 → 增强 → 进化   │  │
│  │  general: 执行   │  │                              │  │
│  │  skill: 学习     │  │  ~/.synapse/skills/          │  │
│  └──────────────────┘  └──────────────────────────────┘  │
└──────────────────────────────────────────────────────────┘
```

一个完整的任务流程：

1. **用户输入** → Agent Runner
2. **LLM 评估复杂度**，决定是否需要搜索技能和工具
3. **搜索**：`task:skill:search` 在技能库中语义匹配，`command:search` 在工具库中检索
4. **加载**：用搜索返回的精确名称 `skill:load` 加载技能指令
5. **LLM 推理**后输出 Shell Command，**BashRouter** 自动路由执行
6. 按需调用 `task:explore` 分发子任务
7. **任务完成后** SkillEnhancer 分析并增强技能，持久化到文件系统

每个组件各司其职，通过统一 Shell 抽象连接——就像大脑不同区域通过神经通路协同工作。

---

## 七、从直觉到验证

回顾最初的八条直觉：

| # | 直觉 | 验证状态 |
|---|------|---------|
| 1 | 工具就是 Agent 的手脚 | ✅ 已知定律，无需证明 |
| 2 | 一切工具都是 Bash | ✅ 三层架构成功运行 |
| 3 | 一切都是工具 | ✅ 子任务/技能管理全部工具化 |
| 4 | 文件系统是一种记忆 | ✅ 已知定律，无需证明 |
| 5 | 技能 = 文件系统 + 工具 | ✅ 已知定律，无需证明 |
| 6 | 技能 + LLM = 大脑 | ✅ 三种进化方式协同工作 |
| 7 | 技能 + LLM + Bash = 通用智能体 | 🔄 持续验证中 |
| 8 | 沙盒 = 一种工作台 | ✅ 重要但非核心——"安全帽" |

关于**沙盒**，最初的设计文档写道："一种工程手段，在现有 LLM 发展阶段的产物，重要但不是 Agent 的核心。"沙盒就像安全帽——工程必备但不是建筑本身。


### 展望

Synapse Agent 目前仍是一个个人项目，还处于一个婴儿期，更多的是体现了我自己对Agent的一种期望和想象。但它验证了一些我认为重要的设计理念：

- **技能市场**：Agent 生成和共享技能，形成"技能应用商店"
- **多 Agent 协作**：从当前的三类子智能体扩展为更复杂的协作拓扑
- **持续进化**：Agent 应该像生物一样，在使用中不断适应和成长

这就是 Synapse 的故事：从八条直觉出发，用一个 Shell 统一工具世界，用文件系统沉淀技能记忆，让 Agent 成为一个会学习的"大脑"。

## 结语

为什么选择这个时候开源呢？因为看到了Obsidian cli 的发布，有异曲同工之处，然后就将最近的思考和实践分享出来。并且可能最近过年也没时间优化，离职准备转型的我需要明年去全力投入到Agent开发中，现在围着简历转了。

未来我将把他打造的更加成熟，加油!

**突触每一次激活，都在让连接变得更强。**

[Github：https://github.com/BaqiF2/Synapse-Agent](https://github.com/BaqiF2/Synapse-Agent)